{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyraysum import prs, Geometry, Model, Control\n",
    "import numpy as np\n",
    "import os\n",
    "import obspy as op\n",
    "import pandas as pd\n",
    "from scipy.optimize import dual_annealing, shgo, differential_evolution\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import LinearConstraint, Bounds\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "path_to_data = \"DATA/RF\"\n",
    "station = \"FCC\"\n",
    "def reading_rfs(keyword: str, filters=(0.05, 0.3), corners = 4, sort=None, t_snr_treshold=-10, path_to_data=\"DATA/waveforms_list.csv\") -> tuple:\n",
    "    \"\"\"\n",
    "    Reading RF data by the name of keyword as station code\n",
    "    inputs:\n",
    "    keyword: str\n",
    "        station code\n",
    "    t_snr_treshold: float\n",
    "        signal to noise ratio treshold for transverse component (default 0, means no treshold)\n",
    "\n",
    "    outputs:\n",
    "    obser: np.array\n",
    "        observed data in numpy array format\n",
    "    baz: list\n",
    "        corresponding back azimuth\n",
    "    slow: list\n",
    "        corresponding slowness\n",
    "    \"\"\"\n",
    "    baz = []\n",
    "    slow = []\n",
    "    waveforms_list = pd.read_csv(\"DATA/waveforms_list.csv\")\n",
    "    filtered_files = waveforms_list[waveforms_list['sta_code']==keyword].copy()\n",
    "    filtered_files = filtered_files[filtered_files['rf_quality'] == 1].copy()\n",
    "    path = \"DATA/RF/\"\n",
    "    npts = 426 * 2   \n",
    "    dt = 0.2\n",
    "    obser = np.zeros((len(filtered_files), npts))\n",
    "    \n",
    "    # function to calculate signal to noise ratio for transverse component\n",
    "    def cal_snr_for_transverse(rft: np.array) -> np.array:\n",
    "        noise = rft[:213]\n",
    "        signal = rft[213:]\n",
    "        return np.sum(np.square(signal)) / np.sum(np.square(noise))\n",
    "    \n",
    "    idx = 0\n",
    "    for _, row in filtered_files.iterrows():\n",
    "        wave_path = os.path.join(path, row['file_name']+\".pkl\")\n",
    "        st = op.read(wave_path)\n",
    "        RFR = st.select(channel=\"RFR\")[0].filter('bandpass', freqmin=filters[0], freqmax=filters[1], corners=corners, zerophase=True).data\n",
    "        RFT = st.select(channel=\"RFT\")[0].filter('bandpass', freqmin=filters[0], freqmax=filters[1], corners=corners, zerophase=True).data\n",
    "        #check if the signal to noise ratio is above the treshold\n",
    "        if cal_snr_for_transverse(RFT) > t_snr_treshold:\n",
    "            baz.append(st[0].stats.baz)\n",
    "            slow.append(st[0].stats.slow)\n",
    "            RFR = RFR / np.max(np.abs(RFR))\n",
    "            RFT = RFT / np.max(np.abs(RFT))\n",
    "            obser[idx, :426] = RFR\n",
    "            obser[idx, 426:] = RFT\n",
    "            idx += 1\n",
    "    obser = obser[:idx, :]\n",
    "    # sorting based on back azimuth or slowness\n",
    "    if sort != None:\n",
    "        zipped = list(zip(obser, baz, slow))\n",
    "        if sort == \"baz\":\n",
    "            zipped.sort(key=lambda x: x[1])\n",
    "        elif sort == \"slow\":\n",
    "            zipped.sort(key=lambda x: x[2])\n",
    "        obser, baz, slow = zip(*zipped)\n",
    "    obser = np.array(obser)\n",
    "    return obser, baz, slow\n",
    "\n",
    "\n",
    "\n",
    "# reading the model\n",
    "def read_model(path_to_models, layer):\n",
    "    \"\"\"\n",
    "    Reading the initials bounds and values\n",
    "    Inputs:\n",
    "        path_to_models: str: path to the models\n",
    "        layer: int: layer number\n",
    "    Outputs:\n",
    "        bounds: list: bounds of the model\n",
    "        fixed_vales: list: fixed values of the model\n",
    "        mask: np.array: mask for the non-fixed values\n",
    "    \"\"\"\n",
    "    bounds = pd.read_csv(os.path.join(path_to_models, \"bounds.csv\"))\n",
    "    fixed_vales = pd.read_csv(os.path.join(path_to_models, \"fixed_values.csv\"))\n",
    "    bounds = bounds[bounds[\"layer_code\"] == layer].drop(columns=[\"layer_code\"])\n",
    "    fixed_vales = fixed_vales[fixed_vales[\"layer_code\"] == layer].drop(columns=[\"layer_code\"])\n",
    "    \n",
    "    #fix a bug\n",
    "    fixed_vales.loc[len(fixed_vales.ani)-1, \"ani\"]=np.nan\n",
    "    \n",
    "    bounds = bounds.values.flatten()\n",
    "    # create a mask for the non-fixed values\n",
    "    mask = pd.notna(bounds)\n",
    "    bounds = [ast.literal_eval(i) for i in bounds if str(i) != 'nan']\n",
    "    return bounds, fixed_vales, mask\n",
    "\n",
    "def pyraysum_func(baz, slow, thickn, rho, vp, vs, dip, strike, plunge, trend, ani, npts, dt) -> tuple:\n",
    "    model = Model(thickn, rho, vp, vs=vs, strike=strike, dip=dip, plunge=plunge, trend=trend, ani=ani)\n",
    "    geom = Geometry(baz, slow)\n",
    "    rc = Control(wvtype=\"P\", rot=\"RTZ\", mults=2, verbose=False, npts=npts*1, dt=dt, align=1, shift=5)\n",
    "    result = prs.run(model, geom, rc, rf=True)\n",
    "    result.filter('rfs', 'lowpass', freq=1., zerophase=True, corners=2)\n",
    "    return result\n",
    "\n",
    "def modeling(model: pd.DataFrame, baz, slow, filters=(0.05, 0.3), corners=4):\n",
    "    result = pyraysum_func(baz, slow, model[\"thickn\"], model[\"rho\"], model[\"vp\"], model[\"vs\"], model[\"dip\"],\n",
    "                                     model[\"strike\"], model[\"plunge\"], model[\"trend\"], model[\"ani\"], 3*426, 0.2)\n",
    "    #lower number of samples would be problematic and that is why we produce longer signal and then reduce it\n",
    "    pred = np.zeros((len(result), 2*426)) \n",
    "    pred_r = np.zeros((len(result), 3*426))\n",
    "    pred_t = np.zeros((len(result), 3*426))\n",
    "\n",
    "    for idx, i in enumerate(result):\n",
    "        RFR = i[1][0].filter('bandpass', freqmin=filters[0], freqmax=filters[1], corners=corners, zerophase=True).data\n",
    "        RFT = i[1][1].filter('bandpass', freqmin=filters[0], freqmax=filters[1], corners=corners, zerophase=True).data\n",
    "        pred_r[idx, :] = RFR / np.max(np.abs(RFR))\n",
    "        pred_t[idx, :] = RFT / np.max(np.abs(RFT))\n",
    "    #making more samples to reduce the effect of the edges\n",
    "    pred_r = pred_r[:, 426:2*426]\n",
    "    pred_t = pred_t[:, 426:2*426]\n",
    "    pred[:, :426], pred[:, 426:] = pred_r, pred_t\n",
    "        #reducing the length of the data to 426\n",
    "    return pred\n",
    "\n",
    "def cost_func(variables, fixed_values, mask, obser, baz, slow, layer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fixed_values = fixed_values.values.flatten()\n",
    "    fixed_values[mask] = variables\n",
    "    model = pd.DataFrame(fixed_values.reshape(-1, len(fixed_values)), columns=fixed_values.index)\n",
    "    pred = modeling(model, baz, slow)\n",
    "    loss = np.sum(np.square(obser - pred))\n",
    "    return loss  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: BLKN - Observation Data Size: (8, 852)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Control \n",
    "filters = (0.05, 0.3)\n",
    "corners = 4\n",
    "#reading RFs\n",
    "path_to_data = \"DATA/RF\"\n",
    "station = \"BLKN\"\n",
    "obser, baz, slow = reading_rfs(station, t_snr_treshold=4, sort=\"baz\", filters=filters, corners=corners)\n",
    "print(\"Station:\", station,\"- Observation Data Size:\", obser.shape)\n",
    "# reading the model bounds and fixed values\n",
    "path_to_models = \"inv/initial\"\n",
    "layer = 2\n",
    "bounds, fixed_values, mask = read_model(path_to_models, layer)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   thickn     rho      vp      vs     dip  strike  plunge   trend   ani\n",
      "0  5000.0  5000.0  5000.0  5000.0     0.0     0.0  5000.0  5000.0  5000\n",
      "1     0.0  3500.0  8100.0  3500.0  5000.0  5000.0  5000.0  5000.0  5000\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isna(fixed_values)\n",
    "fixed_values[mask] = 5000\n",
    "print(fixed_values)\n",
    "\n",
    "# modeling the data\n",
    "results = modeling(fixed_values, baz, slow, filters=filters, corners=corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
